{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with a hardware synthesis tool for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 20:16:18.075136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "import hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tools/Xilinx2019/Vivado/2019.2/bin:/tools/anaconda3/envs/neuralEnv/bin:/home/ro/.local/bin:/usr/local/cuda-11.0/bin:/tools/anaconda3/envs/neuralEnv/bin:/tools/anaconda3/condabin:/home/ro/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path Vivado HLS \n",
    "os.environ['PATH'] = '/tools/Xilinx2019/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 20:16:19.860676: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-09-27 20:16:19.861346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-09-27 20:16:20.254114: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-09-27 20:16:20.254139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mareKaleido\n",
      "2023-09-27 20:16:20.254143: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mareKaleido\n",
      "2023-09-27 20:16:20.254293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.43.4\n",
      "2023-09-27 20:16:20.254305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.43.4\n",
      "2023-09-27 20:16:20.254308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.43.4\n",
      "2023-09-27 20:16:20.254614: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 20:16:20.255071: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80, 80, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (QConv2DBatchnorm)     (None, 80, 80, 2)         65        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 80, 80, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (QConv2DBatchnorm)     (None, 80, 80, 7)         162       \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 80, 80, 7)         0         \n",
      "_________________________________________________________________\n",
      "pool_0 (MaxPooling2D)        (None, 40, 40, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv3 (QConv2DBatchnorm)     (None, 40, 40, 3)         205       \n",
      "_________________________________________________________________\n",
      "relu3 (QActivation)          (None, 40, 40, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (QConv2DBatchnorm)     (None, 40, 40, 5)         161       \n",
      "_________________________________________________________________\n",
      "relu4 (QActivation)          (None, 40, 40, 5)         0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 20, 20, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 2)                 4002      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,595\n",
      "Trainable params: 4,557\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n",
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80, 80, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (QConv2DBatchnorm)     (None, 80, 80, 2)         65        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 80, 80, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (QConv2DBatchnorm)     (None, 80, 80, 7)         162       \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 80, 80, 7)         0         \n",
      "_________________________________________________________________\n",
      "pool_0 (MaxPooling2D)        (None, 40, 40, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv3 (QConv2DBatchnorm)     (None, 40, 40, 3)         205       \n",
      "_________________________________________________________________\n",
      "relu3 (QActivation)          (None, 40, 40, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (QConv2DBatchnorm)     (None, 40, 40, 5)         161       \n",
      "_________________________________________________________________\n",
      "relu4 (QActivation)          (None, 40, 40, 5)         0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 20, 20, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 2)                 4002      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,595\n",
      "Trainable params: 4,557\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load keras model \n",
    "\n",
    "#distilled_student_1D\n",
    "\n",
    "model = load_model('../compressionAndTraining/models/distilled_student_2D.h5', custom_objects={'QConv2DBatchnorm':QConv2DBatchnorm,'quantized_bits':quantized_bits, 'QActivation': QActivation, 'QDense': QDense})\n",
    "model.summary()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hls4ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: conv1, layer type: QConv2DBatchnorm\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: conv2, layer type: QConv2DBatchnorm\n",
      "Layer name: relu2, layer type: QActivation\n",
      "Layer name: pool_0, layer type: MaxPooling2D\n",
      "Layer name: conv3, layer type: QConv2DBatchnorm\n",
      "Layer name: relu3, layer type: QActivation\n",
      "Layer name: conv4, layer type: QConv2DBatchnorm\n",
      "Layer name: relu4, layer type: QActivation\n",
      "Layer name: pool_1, layer type: MaxPooling2D\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 80, 80, 3]], output shape: [None, 80, 80, 3]\n",
      "Layer name: conv1, layer type: QConv2DBatchnorm, input shapes: [[None, 80, 80, 3]], output shape: [None, 80, 80, 2]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 80, 80, 2]], output shape: [None, 80, 80, 2]\n",
      "Layer name: conv2, layer type: QConv2DBatchnorm, input shapes: [[None, 80, 80, 2]], output shape: [None, 80, 80, 7]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 80, 80, 7]], output shape: [None, 80, 80, 7]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, input shapes: [[None, 80, 80, 7]], output shape: [None, 40, 40, 7]\n",
      "Layer name: conv3, layer type: QConv2DBatchnorm, input shapes: [[None, 40, 40, 7]], output shape: [None, 40, 40, 3]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 40, 40, 3]], output shape: [None, 40, 40, 3]\n",
      "Layer name: conv4, layer type: QConv2DBatchnorm, input shapes: [[None, 40, 40, 3]], output shape: [None, 40, 40, 5]\n",
      "Layer name: relu4, layer type: Activation, input shapes: [[None, 40, 40, 5]], output shape: [None, 40, 40, 5]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, input shapes: [[None, 40, 40, 5]], output shape: [None, 20, 20, 5]\n",
      "Layer name: flatten_1, layer type: Reshape, input shapes: [[None, 20, 20, 5]], output shape: [None, 2000]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 2000]], output shape: [None, 2]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Based on the tutorials provided by hls4ml\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<8,4>'\n",
    "\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Latency'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "\n",
    "#hls_config['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg['IOType']     = 'io_stream' # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir']  = 'model_mobileNet/'\n",
    "cfg['XilinxPart'] = 'xczu9eg-ffvb1156-2-e'  # PYNQ-Z1 or Zedboard: xc7z020-clg484-1\n",
    "  \n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "hls_model.compile()\n",
    "\n",
    "hls_model.build(csim=False, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
