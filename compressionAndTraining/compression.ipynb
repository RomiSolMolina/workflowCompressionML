{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:55:47.612097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.studentOptimization_1D import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherOptimization2D_SOTA import *\n",
    "\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n",
    "\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:55:49.088966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-11 14:55:49.119761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 14:55:49.119928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2023-07-11 14:55:49.119943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 14:55:49.120997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 14:55:49.121052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-11 14:55:49.122077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-11 14:55:49.122260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-11 14:55:49.123218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-11 14:55:49.123776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-11 14:55:49.125960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-11 14:55:49.126056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 14:55:49.126183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 14:55:49.126257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH_2D = \"dataset/pestControl\"\n",
    "ROOT_PATH_1D = r'dataset/cluster'\n",
    "\n",
    "\n",
    "# Class labels \n",
    "classLabels_2D = ['0', '1', '2']\n",
    "classLabels_1D = ['0', '1', '2', '3']\n",
    "\n",
    "nLabels = len(classLabels_1D)\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLES = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 0\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 1\n",
    "N_ITERATIONS_STUDENT = 100\n",
    "\n",
    "# Type of input -->  1: 1D signal, 2: 2D signal, 3: state-of-the art dataset\n",
    "D_SIGNAL = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel normalization\n",
    "def normalizationPix(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_ = train.astype('float32')\n",
    "    test_ = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_ = train_ / 255.0\n",
    "    test_ = test_ / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    # Load 1D signal dataset\n",
    "    xTrain, xTest, xTest_df_Final, yTrain, yTest, yTest_Final = loadDataset_1D(ROOT_PATH_1D, nLabels, SAMPLES)\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH_2D, classLabels_2D, ROWS, COLS)\n",
    "else: \n",
    "    # CIFAR-10 dataset\n",
    "    from keras.datasets import cifar10\n",
    "    (images_train, y_train), (images_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    images_train, images_test = normalizationPix(images_train, images_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "    \n",
    "    \n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV+1):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "        print(UPPER_CONV)\n",
    "    for j in range (1, UPPER_FC+1):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "        print(UPPER_FC)\n",
    "    \n",
    "    print(\"Best hyper-parameter configuration: \", bestHP)\n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher optimization\n",
      "INFO:tensorflow:Reloading Oracle from existing project tuner_teacher/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner_teacher/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f1fc71ebc10>\n"
     ]
    }
   ],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    \n",
    "    if D_SIGNAL == 1:\n",
    "        print(\"1D signal\")\n",
    "        bestHP_BO_teacher = teacherBO_1D(xTrain, xTest, yTrain, yTest)\n",
    "    elif D_SIGNAL == 2:\n",
    "        print(\"2D signal\")\n",
    "        bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "        # Grab the best hyperparameters\n",
    "    else: \n",
    "        bestHP_BO_teacher = teacherBO_SOTA(images_train, y_train, images_test, y_test, N_ITERATIONS_TEACHER)\n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacherModel = load_model('models/CNN/teacher_NEW_v2_ok.h5')    \n",
    "    \n",
    "    teacherModel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "Best hyper-parameter configuration:  [64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "[64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "Tacher SOTA\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All layers added to a Sequential model should have unique names. Name \"relu3\" is already the name of a layer in this model. Update the `name` argument to pass a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X16sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(bestHP_BO_teacher)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X16sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Train 2D teacher model - SOTA dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X16sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m teacherModel \u001b[39m=\u001b[39m teacherTrainingAfterBPO_SOTA(bestHP_BO_teacher, images_train, images_test, y_train, y_test, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X16sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m teacherModel\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X16sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Save model 2D teacher model\u001b[39;00m\n",
      "File \u001b[0;32m~/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/teacherTraining2D_SOTA.py:8\u001b[0m, in \u001b[0;36mteacherTrainingAfterBPO_SOTA\u001b[0;34m(bestHP, xTrain, xTest, yTrain, yTest, lr)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTacher SOTA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m bestHP \u001b[39m=\u001b[39m [\u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m96\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m20\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m modelTeacherDefinition_2D_SOTA(bestHP)\n\u001b[1;32m     10\u001b[0m adam \u001b[39m=\u001b[39m Adam(lr)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39madam, loss\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m], metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/modelTeacher2D_SOTA.py:28\u001b[0m, in \u001b[0;36mmodelTeacherDefinition_2D_SOTA\u001b[0;34m(bestHP)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodelTeacherDefinition_2D_SOTA\u001b[39m(bestHP):\n\u001b[0;32m---> 28\u001b[0m     teacherCNN_SOTA \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mSequential(\n\u001b[1;32m     29\u001b[0m         [\n\u001b[1;32m     30\u001b[0m             keras\u001b[39m.\u001b[39;49mInput(shape\u001b[39m=\u001b[39;49m(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m3\u001b[39;49m)),\n\u001b[1;32m     31\u001b[0m             \n\u001b[1;32m     32\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m0\u001b[39;49m], (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_1\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     33\u001b[0m             layers\u001b[39m.\u001b[39;49mBatchNormalization(),\n\u001b[1;32m     34\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu1\u001b[39;49m\u001b[39m'\u001b[39;49m),        \n\u001b[1;32m     35\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m1\u001b[39;49m], (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_2\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     36\u001b[0m             layers\u001b[39m.\u001b[39;49mBatchNormalization(),        \n\u001b[1;32m     37\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu2\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     38\u001b[0m             layers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)), \n\u001b[1;32m     39\u001b[0m             \n\u001b[1;32m     40\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m2\u001b[39;49m], (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_3\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     41\u001b[0m             layers\u001b[39m.\u001b[39;49mBatchNormalization(),        \n\u001b[1;32m     42\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu3\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     43\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m3\u001b[39;49m],  (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_4\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     44\u001b[0m             layers\u001b[39m.\u001b[39;49mBatchNormalization(),          \n\u001b[1;32m     45\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu3a\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     46\u001b[0m             layers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),       \n\u001b[1;32m     47\u001b[0m             \n\u001b[1;32m     48\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m4\u001b[39;49m], (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_5\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     49\u001b[0m             layers\u001b[39m.\u001b[39;49mConv2D(bestHP[\u001b[39m5\u001b[39;49m], (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv_6\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu3\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     52\u001b[0m             layers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)), \n\u001b[1;32m     53\u001b[0m             \n\u001b[1;32m     54\u001b[0m             layers\u001b[39m.\u001b[39;49mFlatten(),\n\u001b[1;32m     55\u001b[0m             \n\u001b[1;32m     56\u001b[0m             layers\u001b[39m.\u001b[39;49mDense(bestHP[\u001b[39m6\u001b[39;49m], name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfc1\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     57\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu4\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     58\u001b[0m             \n\u001b[1;32m     59\u001b[0m             layers\u001b[39m.\u001b[39;49mDense(bestHP[\u001b[39m7\u001b[39;49m], name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfc2\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     60\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu5\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     61\u001b[0m             layers\u001b[39m.\u001b[39;49mDense(bestHP[\u001b[39m8\u001b[39;49m], name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfc3\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     62\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu6\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m             \n\u001b[1;32m     65\u001b[0m             layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_regularizer\u001b[39m=\u001b[39;49ml2(\u001b[39m0.0001\u001b[39;49m)),\n\u001b[1;32m     66\u001b[0m             layers\u001b[39m.\u001b[39;49mActivation(activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     67\u001b[0m             \n\u001b[1;32m     68\u001b[0m         ],\n\u001b[1;32m     69\u001b[0m         name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mteacherCNN_SOTA\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     teacherCNN_SOTA\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m teacherCNN_SOTA\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:517\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    518\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:144\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m   layers \u001b[39m=\u001b[39m [layers]\n\u001b[1;32m    143\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[0;32m--> 144\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(layer)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:517\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    518\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:188\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    186\u001b[0m tf_utils\u001b[39m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[0;32m--> 188\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAll layers added to a Sequential model \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    189\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mshould have unique names. Name \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is already the name\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    190\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m of a layer in this model. Update the `name` argument \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    191\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mto pass a unique name.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (layer\u001b[39m.\u001b[39mname,))\n\u001b[1;32m    193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    194\u001b[0m set_inputs \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: All layers added to a Sequential model should have unique names. Name \"relu3\" is already the name of a layer in this model. Update the `name` argument to pass a unique name."
     ]
    }
   ],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "if TEACHER_OP == 0:\n",
    "    if D_SIGNAL == 1:\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 0\n",
    "        UPPER_FC = 5\n",
    "\n",
    "        # Grab best hyperparams\n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 1D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, xTrain, xTest, yTrain, yTest, lr)\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 1D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "    elif D_SIGNAL == 2:\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 4\n",
    "        UPPER_FC = 3\n",
    "        \n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "        # Train 2D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D.h5\")\n",
    "    \n",
    "    elif D_SIGNAL == 3:\n",
    "        from src.teacherTraining2D_SOTA import teacherTrainingAfterBPO_SOTA\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 8\n",
    "        UPPER_FC = 3    \n",
    "\n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 2D teacher model - SOTA dataset\n",
    "        teacherModel = teacherTrainingAfterBPO_SOTA(bestHP_BO_teacher, images_train, images_test, y_train, y_test, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D_SOTA.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "if D_SIGNAL == 1:\n",
    "    bestHP_BO = studentBO_1D(xTrain, xTest, yTrain, yTest, teacherModel, N_ITERATIONS_STUDENT)\n",
    "else:\n",
    "    bestHP_BO = studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 0\n",
    "    UPPER_FC = 2\n",
    "\n",
    "    # Grab best hyperparams\n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "    print(bestHP_BO_student)\n",
    "        \n",
    "    # Train 1D teacher model\n",
    "    studentModel = studentCompression_1D(bestHP_BO_student, xTrain, xTest, yTrain, yTest, teacherModel, lr)\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 1D teacher model\n",
    "    #studentModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "else:\n",
    "\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression(bestHP_BO_student, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "if D_SIGNAL == 1:\n",
    "    # 1D signal\n",
    "    confusionMatrixPlot(studentModel, xTest_df_Final, yTest_Final)\n",
    "\n",
    "else:\n",
    "    # 2D signal\n",
    "    confusionMatrixPlot(studentModel, images_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
