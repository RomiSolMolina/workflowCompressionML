{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH = \"/home/ro/kaleido/research/repo/pestControl/dataset\"\n",
    "# Class labels \n",
    "classLabels=['0', '1', '2']\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLEs = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 1\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 2\n",
    "N_ITERATIONS_STUDENT = 2\n",
    "\n",
    "# Type of input - 1: 1D signal or 2: 2D signal\n",
    "D_SIGNAL = 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == '1':\n",
    "    # Load 1D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH, classLabels, ROWS, COLS)\n",
    "\n",
    "else:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH, classLabels, ROWS, COLS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "\n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "    for j in range (1, UPPER_FC):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "    \n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "    # Grab the best hyperparameters\n",
    "        \n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacher_baseline = load_model('/home/ro/kaleido/research/repo/Methodology_MLclassificationSoC/ML_src/models/CNN/teacher_NEW_v2_ok.h5')  #RPIC modified\n",
    "   # teacher_baseline = load_model('../compressionAndTraining/models/preTrained/teacher_NEW_v2_ok.h5')  #RPIC modified\n",
    "    teacher_baseline.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "lr = bestHP_BO_teacher.get('learning_rate')\n",
    "CONV_VAR = 'conv_'\n",
    "FC_VAR = 'fc'\n",
    "UPPER_CONV = 4\n",
    "UPPER_FC = 3\n",
    "\n",
    "bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacher_baseline, lr)\n",
    "teacherModel.summary()\n",
    "\n",
    "# Save model \n",
    "teacherModel.save(\"models/teacherFP.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "bestHP_BO = studentBO(images_train, y_train, images_test, y_test, teacher_baseline, N_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters for student training\n",
    "CONV_VAR = 'conv_'\n",
    "FC_VAR = 'fc'\n",
    "UPPER_CONV = 9\n",
    "UPPER_FC = 4\n",
    "lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "bestHP = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training to obtain compressed model\n",
    "model = studentCompression(bestHP, images_train, y_train, teacher_baseline, lr)\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "model.save(\"models/distilled_student.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "confusionMatrixPlot(model, images_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with a hardware synthesis tool for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware assessment framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating IP core though High-level Synthesis, the developer should integrate it with the corresponding design. Source files are in the folder: assessmentFramework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
