{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.studentOptimization_1D import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherOptimization2D_SOTA import *\n",
    "from src.studentOptimization2D_SOTA import *\n",
    "\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n",
    "\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH_2D = \"dataset/pestControl\"\n",
    "ROOT_PATH_1D = r'dataset/cluster'\n",
    "\n",
    "\n",
    "# Class labels \n",
    "classLabels_2D = ['0', '1', '2']\n",
    "classLabels_1D = ['0', '1', '2', '3']\n",
    "\n",
    "nLabels = len(classLabels_1D)\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLES = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 0\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 1\n",
    "N_ITERATIONS_STUDENT = 1\n",
    "\n",
    "# Type of input -->  1: 1D signal, 2: 2D signal, 3: state-of-the art dataset\n",
    "D_SIGNAL = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel normalization\n",
    "def normalizationPix(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_ = train.astype('float32')\n",
    "    test_ = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_ = train_ / 255.0\n",
    "    test_ = test_ / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    # Load 1D signal dataset\n",
    "    xTrain, xTest, xTest_df_Final, yTrain, yTest, yTest_Final = loadDataset_1D(ROOT_PATH_1D, nLabels, SAMPLES)\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH_2D, classLabels_2D, ROWS, COLS)\n",
    "else: \n",
    "    # CIFAR-10 dataset\n",
    "    from keras.datasets import cifar10\n",
    "    (images_train, y_train), (images_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    images_train, images_test = normalizationPix(images_train, images_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "    \n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV+1):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "    for j in range (1, UPPER_FC+1):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "   \n",
    "    print(\"Best hyper-parameter configuration: \", bestHP)\n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher optimization\n",
      "INFO:tensorflow:Reloading Oracle from existing project tuner_teacher/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner_teacher/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 16:52:37.410588: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 16:52:37.432046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304000000 Hz\n",
      "2023-07-11 16:52:37.433455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x146f150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-11 16:52:37.433478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-07-11 16:52:37.485815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.486047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15b4b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-11 16:52:37.486060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2023-07-11 16:52:37.486246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.486365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2023-07-11 16:52:37.486389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 16:52:37.486428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 16:52:37.486435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-11 16:52:37.486441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-11 16:52:37.486448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-11 16:52:37.486455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-11 16:52:37.486462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-11 16:52:37.486469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-11 16:52:37.486502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.486597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.486701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-11 16:52:37.486721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 16:52:37.763223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-11 16:52:37.763243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-11 16:52:37.763247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-11 16:52:37.763459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.763590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 16:52:37.763678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1198 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    \n",
    "    if D_SIGNAL == 1:\n",
    "        print(\"1D signal\")\n",
    "        bestHP_BO_teacher = teacherBO_1D(xTrain, xTest, yTrain, yTest)\n",
    "    elif D_SIGNAL == 2:\n",
    "        print(\"2D signal\")\n",
    "        bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "        # Grab the best hyperparameters\n",
    "    else: \n",
    "        bestHP_BO_teacher = teacherBO_SOTA(images_train, y_train, images_test, y_test, N_ITERATIONS_TEACHER)\n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacherModel = load_model('models/CNN/teacher_NEW_v2_ok.h5')    \n",
    "    \n",
    "    teacherModel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter configuration:  [64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "Tacher SOTA\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 16:52:38.152038: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2023-07-11 16:52:38.353653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 16:52:38.882457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 16:52:39.009205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/391 [..............................] - ETA: 13s - loss: 2.3718 - accuracy: 0.1124  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 16:52:40.006012: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2023-07-11 16:52:40.020733: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1023.69M (1073414144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-07-11 16:52:40.020944: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 921.32M (966072832 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 38ms/step - loss: 2.0916 - accuracy: 0.2622 - val_loss: 2.1947 - val_accuracy: 0.1996\n",
      "Epoch 2/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.4105 - accuracy: 0.5230 - val_loss: 1.2318 - val_accuracy: 0.5736\n",
      "Epoch 3/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1507 - accuracy: 0.6127 - val_loss: 1.1266 - val_accuracy: 0.6163\n",
      "Epoch 4/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0228 - accuracy: 0.6588 - val_loss: 1.0374 - val_accuracy: 0.6520\n",
      "Epoch 5/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9291 - accuracy: 0.6917 - val_loss: 0.9473 - val_accuracy: 0.6794\n",
      "Epoch 6/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.8671 - accuracy: 0.7117 - val_loss: 0.9689 - val_accuracy: 0.6726\n",
      "Epoch 7/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.7957 - accuracy: 0.7406 - val_loss: 0.9189 - val_accuracy: 0.6980\n",
      "Epoch 8/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.7524 - accuracy: 0.7537 - val_loss: 0.8865 - val_accuracy: 0.7140\n",
      "Epoch 9/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.7272 - accuracy: 0.7623 - val_loss: 0.8587 - val_accuracy: 0.7224\n",
      "Epoch 10/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6724 - accuracy: 0.7841 - val_loss: 0.8270 - val_accuracy: 0.7294\n",
      "Epoch 11/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.6397 - accuracy: 0.7949 - val_loss: 0.9003 - val_accuracy: 0.7043\n",
      "Epoch 12/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6061 - accuracy: 0.8072 - val_loss: 0.8475 - val_accuracy: 0.7251\n",
      "Epoch 13/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5738 - accuracy: 0.8172 - val_loss: 0.8303 - val_accuracy: 0.7309\n",
      "Epoch 14/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5511 - accuracy: 0.8259 - val_loss: 0.7914 - val_accuracy: 0.7434\n",
      "Epoch 15/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5247 - accuracy: 0.8324 - val_loss: 0.7858 - val_accuracy: 0.7509\n",
      "Epoch 16/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4896 - accuracy: 0.8504 - val_loss: 0.8610 - val_accuracy: 0.7335\n",
      "Epoch 17/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4775 - accuracy: 0.8525 - val_loss: 0.8684 - val_accuracy: 0.7338\n",
      "Epoch 18/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4413 - accuracy: 0.8686 - val_loss: 0.8115 - val_accuracy: 0.7459\n",
      "Epoch 19/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4231 - accuracy: 0.8725 - val_loss: 0.8053 - val_accuracy: 0.7549\n",
      "Epoch 20/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3978 - accuracy: 0.8821 - val_loss: 0.8096 - val_accuracy: 0.7512\n",
      "Epoch 21/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3743 - accuracy: 0.8917 - val_loss: 0.8457 - val_accuracy: 0.7476\n",
      "Epoch 22/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3574 - accuracy: 0.8982 - val_loss: 0.8178 - val_accuracy: 0.7508\n",
      "Epoch 23/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3291 - accuracy: 0.9078 - val_loss: 0.8241 - val_accuracy: 0.7542\n",
      "Epoch 24/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3203 - accuracy: 0.9112 - val_loss: 0.8280 - val_accuracy: 0.7581\n",
      "Epoch 25/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2897 - accuracy: 0.9232 - val_loss: 0.8606 - val_accuracy: 0.7546\n",
      "Epoch 26/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2772 - accuracy: 0.9290 - val_loss: 0.9347 - val_accuracy: 0.7301\n",
      "Epoch 27/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2599 - accuracy: 0.9327 - val_loss: 0.8993 - val_accuracy: 0.7487\n",
      "Epoch 28/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2368 - accuracy: 0.9428 - val_loss: 1.0383 - val_accuracy: 0.7302\n",
      "Epoch 29/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2294 - accuracy: 0.9442 - val_loss: 0.9212 - val_accuracy: 0.7559\n",
      "Epoch 30/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2087 - accuracy: 0.9532 - val_loss: 0.9783 - val_accuracy: 0.7488\n",
      "Epoch 31/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.1935 - accuracy: 0.9586 - val_loss: 1.0287 - val_accuracy: 0.7424\n",
      "Epoch 32/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.1869 - accuracy: 0.9597 - val_loss: 1.1467 - val_accuracy: 0.7253\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "if TEACHER_OP == 0:\n",
    "    if D_SIGNAL == 1:\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 0\n",
    "        UPPER_FC = 5\n",
    "\n",
    "        # Grab best hyperparams\n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 1D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, xTrain, xTest, yTrain, yTest, lr)\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 1D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "    elif D_SIGNAL == 2:\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 4\n",
    "        UPPER_FC = 3\n",
    "        \n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "        # Train 2D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D.h5\")\n",
    "    \n",
    "    elif D_SIGNAL == 3:\n",
    "        from src.teacherTraining2D_SOTA import teacherTrainingAfterBPO_SOTA\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 8\n",
    "        UPPER_FC = 3    \n",
    "\n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "       \n",
    "        # Train 2D teacher model - SOTA dataset\n",
    "        teacherModel = teacherTrainingAfterBPO_SOTA(bestHP_BO_teacher, images_train, images_test, y_train, y_test, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D_SOTA.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner/untitled_project/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "if D_SIGNAL == 1:\n",
    "    bestHP_BO = studentBO_1D(xTrain, xTest, yTrain, yTest, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 2:\n",
    "    bestHP_BO = studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 3:\n",
    "    bestHP_BO = studentBO_2D_SOTA(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter configuration:  [2, 5, 3, 10, 7, 9, 2, 10, 5, 5, 5]\n",
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (QConv2DBatchnorm)     (None, 32, 32, 2)         65        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (QConv2DBatchnorm)     (None, 32, 32, 5)         116       \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 32, 32, 5)         0         \n",
      "_________________________________________________________________\n",
      "pool_0 (MaxPooling2D)        (None, 16, 16, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv3 (QConv2DBatchnorm)     (None, 16, 16, 3)         151       \n",
      "_________________________________________________________________\n",
      "relu3 (QActivation)          (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (QConv2DBatchnorm)     (None, 16, 16, 10)        321       \n",
      "_________________________________________________________________\n",
      "relu4 (QActivation)          (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (QConv2DBatchnorm)     (None, 8, 8, 7)           666       \n",
      "_________________________________________________________________\n",
      "relu5 (QActivation)          (None, 8, 8, 7)           0         \n",
      "_________________________________________________________________\n",
      "conv6 (QConv2DBatchnorm)     (None, 8, 8, 9)           613       \n",
      "_________________________________________________________________\n",
      "relu6 (QActivation)          (None, 8, 8, 9)           0         \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 4, 4, 9)           0         \n",
      "_________________________________________________________________\n",
      "conv7 (QConv2DBatchnorm)     (None, 4, 4, 2)           173       \n",
      "_________________________________________________________________\n",
      "relu7 (QActivation)          (None, 4, 4, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv8 (QConv2DBatchnorm)     (None, 4, 4, 10)          231       \n",
      "_________________________________________________________________\n",
      "relu8 (QActivation)          (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 2, 2, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "q_dense_3 (QDense)           (None, 5)                 205       \n",
      "_________________________________________________________________\n",
      "relu1_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "q_dense_4 (QDense)           (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "relu2_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "q_dense_5 (QDense)           (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "relu3_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "output_softmax (QActivation) (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,619\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "2023-07-11 17:03:16.644649: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_46637/2202798754.py\", line 49, in <cell line: 1>\n",
      "    studentModel = studentCompression_2D_SOTA(bestHP_BO_student, images_train, images_test, y_train, y_test, teacherModel, lr)\n",
      "  File \"/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/studentCompression.py\", line 186, in studentCompression_2D_SOTA\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 725, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3196, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/distillationClassKeras.py:60 train_step\n",
      "        distillation_loss = self.distillation_loss_fn(\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:152 __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:256 call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1652 kl_divergence\n",
      "        return math_ops.reduce_sum(y_true * math_ops.log(y_true / y_pred), axis=-1)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n",
      "        raise e\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n",
      "        return func(x, y, name=name)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1336 truediv\n",
      "        return _truediv_python3(x, y, name)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1275 _truediv_python3\n",
      "        return gen_math_ops.real_div(x, y, name=name)\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:7346 real_div\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 10 and 3 for '{{node kl_divergence/truediv}} = RealDiv[T=DT_FLOAT](kl_divergence/clip_by_value, kl_divergence/clip_by_value_1)' with input shapes: [?,10], [?,3].\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 0\n",
    "    UPPER_FC = 2\n",
    "\n",
    "    # Grab best hyperparams\n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "    print(bestHP_BO_student)\n",
    "        \n",
    "    # Train 1D teacher model\n",
    "    studentModel = studentCompression_1D(bestHP_BO_student, xTrain, xTest, yTrain, yTest, teacherModel, lr)\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 1D teacher model\n",
    "    #studentModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression(bestHP_BO_student, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D.h5\")\n",
    "elif D_SIGNAL == 3:\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 8\n",
    "    UPPER_FC = 3\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression_2D_SOTA(bestHP_BO_student, images_train, images_test, y_train, y_test, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D_SOTA.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "if D_SIGNAL == 1:\n",
    "    # 1D signal\n",
    "    confusionMatrixPlot(studentModel, xTest_df_Final, yTest_Final)\n",
    "\n",
    "else:\n",
    "    # 2D signal\n",
    "    confusionMatrixPlot(studentModel, images_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
