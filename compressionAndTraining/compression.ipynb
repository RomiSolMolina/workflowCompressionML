{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.studentOptimization_1D import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherOptimization2D_SOTA import *\n",
    "from src.studentOptimization2D_SOTA import *\n",
    "\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n",
    "\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH_2D = \"dataset/pestControl\"\n",
    "ROOT_PATH_1D = r'dataset/cluster'\n",
    "\n",
    "\n",
    "# Class labels \n",
    "classLabels_2D = ['0', '1', '2']\n",
    "classLabels_1D = ['0', '1', '2', '3']\n",
    "\n",
    "nLabels = len(classLabels_1D)\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLES = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 0\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 1\n",
    "N_ITERATIONS_STUDENT = 1\n",
    "\n",
    "# Type of input -->  1: 1D signal, 2: 2D signal, 3: state-of-the art dataset\n",
    "D_SIGNAL = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel normalization\n",
    "def normalizationPix(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_ = train.astype('float32')\n",
    "    test_ = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_ = train_ / 255.0\n",
    "    test_ = test_ / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    # Load 1D signal dataset\n",
    "    xTrain, xTest, xTest_df_Final, yTrain, yTest, yTest_Final = loadDataset_1D(ROOT_PATH_1D, nLabels, SAMPLES)\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH_2D, classLabels_2D, ROWS, COLS)\n",
    "else: \n",
    "    # CIFAR-10 dataset\n",
    "    from keras.datasets import cifar10\n",
    "    (images_train, y_train), (images_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    images_train, images_test = normalizationPix(images_train, images_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "    \n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV+1):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "    for j in range (1, UPPER_FC+1):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "   \n",
    "    print(\"Best hyper-parameter configuration: \", bestHP)\n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher optimization\n",
      "INFO:tensorflow:Reloading Oracle from existing project tuner_teacher/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner_teacher/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    \n",
    "    if D_SIGNAL == 1:\n",
    "        print(\"1D signal\")\n",
    "        bestHP_BO_teacher = teacherBO_1D(xTrain, xTest, yTrain, yTest)\n",
    "    elif D_SIGNAL == 2:\n",
    "        print(\"2D signal\")\n",
    "        bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "        # Grab the best hyperparameters\n",
    "    else: \n",
    "        bestHP_BO_teacher = teacherBO_SOTA(images_train, y_train, images_test, y_test, N_ITERATIONS_TEACHER)\n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacherModel = load_model('models/CNN/teacher_NEW_v2_ok.h5')    \n",
    "    \n",
    "    teacherModel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter configuration:  [64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "Tacher SOTA\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 17:05:15.258045: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 1.9909 - accuracy: 0.2880 - val_loss: 2.1075 - val_accuracy: 0.2115\n",
      "Epoch 2/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.3184 - accuracy: 0.5420 - val_loss: 1.2692 - val_accuracy: 0.5669\n",
      "Epoch 3/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.1057 - accuracy: 0.6202 - val_loss: 1.1459 - val_accuracy: 0.6125\n",
      "Epoch 4/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.9844 - accuracy: 0.6740 - val_loss: 1.1009 - val_accuracy: 0.6305\n",
      "Epoch 5/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.8965 - accuracy: 0.7031 - val_loss: 0.9830 - val_accuracy: 0.6786\n",
      "Epoch 6/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.8176 - accuracy: 0.7306 - val_loss: 0.9359 - val_accuracy: 0.6892\n",
      "Epoch 7/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.7629 - accuracy: 0.7530 - val_loss: 0.9251 - val_accuracy: 0.6939\n",
      "Epoch 8/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.7105 - accuracy: 0.7705 - val_loss: 0.9209 - val_accuracy: 0.7024\n",
      "Epoch 9/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6747 - accuracy: 0.7837 - val_loss: 0.8787 - val_accuracy: 0.7176\n",
      "Epoch 10/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6356 - accuracy: 0.7980 - val_loss: 0.8463 - val_accuracy: 0.7318\n",
      "Epoch 11/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.6009 - accuracy: 0.8102 - val_loss: 0.9603 - val_accuracy: 0.6952\n",
      "Epoch 12/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5648 - accuracy: 0.8232 - val_loss: 0.8403 - val_accuracy: 0.7338\n",
      "Epoch 13/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5388 - accuracy: 0.8316 - val_loss: 0.8369 - val_accuracy: 0.7393\n",
      "Epoch 14/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5062 - accuracy: 0.8433 - val_loss: 0.8540 - val_accuracy: 0.7305\n",
      "Epoch 15/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4788 - accuracy: 0.8548 - val_loss: 0.8013 - val_accuracy: 0.7515\n",
      "Epoch 16/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4491 - accuracy: 0.8642 - val_loss: 0.8193 - val_accuracy: 0.7501\n",
      "Epoch 17/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.4322 - accuracy: 0.8703 - val_loss: 0.8420 - val_accuracy: 0.7425\n",
      "Epoch 18/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4067 - accuracy: 0.8796 - val_loss: 0.8828 - val_accuracy: 0.7336\n",
      "Epoch 19/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.3735 - accuracy: 0.8937 - val_loss: 0.9182 - val_accuracy: 0.7321\n",
      "Epoch 20/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3595 - accuracy: 0.8983 - val_loss: 0.8537 - val_accuracy: 0.7468\n",
      "Epoch 21/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.3304 - accuracy: 0.9072 - val_loss: 0.9156 - val_accuracy: 0.7387\n",
      "Epoch 22/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.3066 - accuracy: 0.9175 - val_loss: 0.9054 - val_accuracy: 0.7473\n",
      "Epoch 23/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.2893 - accuracy: 0.9257 - val_loss: 0.9244 - val_accuracy: 0.7429\n",
      "Epoch 24/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2760 - accuracy: 0.9304 - val_loss: 0.8917 - val_accuracy: 0.7516\n",
      "Epoch 25/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.2504 - accuracy: 0.9394 - val_loss: 0.9587 - val_accuracy: 0.7414\n",
      "Epoch 26/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.2327 - accuracy: 0.9458 - val_loss: 0.9012 - val_accuracy: 0.7584\n",
      "Epoch 27/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.2136 - accuracy: 0.9525 - val_loss: 0.9356 - val_accuracy: 0.7548\n",
      "Epoch 28/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.1938 - accuracy: 0.9607 - val_loss: 1.0252 - val_accuracy: 0.7377\n",
      "Epoch 29/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.1815 - accuracy: 0.9644 - val_loss: 0.9943 - val_accuracy: 0.7495\n",
      "Epoch 30/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.1705 - accuracy: 0.9676 - val_loss: 1.0660 - val_accuracy: 0.7451\n",
      "Epoch 31/32\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.1581 - accuracy: 0.9729 - val_loss: 1.0789 - val_accuracy: 0.7495\n",
      "Epoch 32/32\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1390 - accuracy: 0.9799 - val_loss: 1.1545 - val_accuracy: 0.7352\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "if TEACHER_OP == 0:\n",
    "    if D_SIGNAL == 1:\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 0\n",
    "        UPPER_FC = 5\n",
    "\n",
    "        # Grab best hyperparams\n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 1D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, xTrain, xTest, yTrain, yTest, lr)\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 1D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "    elif D_SIGNAL == 2:\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 4\n",
    "        UPPER_FC = 3\n",
    "        \n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "        # Train 2D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D.h5\")\n",
    "    \n",
    "    elif D_SIGNAL == 3:\n",
    "        from src.teacherTraining2D_SOTA import teacherTrainingAfterBPO_SOTA\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 8\n",
    "        UPPER_FC = 3    \n",
    "\n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "       \n",
    "        # Train 2D teacher model - SOTA dataset\n",
    "        teacherModel = teacherTrainingAfterBPO_SOTA(bestHP_BO_teacher, images_train, images_test, y_train, y_test, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D_SOTA.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner/untitled_project/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "if D_SIGNAL == 1:\n",
    "    bestHP_BO = studentBO_1D(xTrain, xTest, yTrain, yTest, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 2:\n",
    "    bestHP_BO = studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 3:\n",
    "    bestHP_BO = studentBO_2D_SOTA(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter configuration:  [2, 5, 3, 10, 7, 9, 2, 10, 5, 5, 5]\n",
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (QConv2DBatchnorm)     (None, 32, 32, 2)         65        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (QConv2DBatchnorm)     (None, 32, 32, 5)         116       \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 32, 32, 5)         0         \n",
      "_________________________________________________________________\n",
      "pool_0 (MaxPooling2D)        (None, 16, 16, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv3 (QConv2DBatchnorm)     (None, 16, 16, 3)         151       \n",
      "_________________________________________________________________\n",
      "relu3 (QActivation)          (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (QConv2DBatchnorm)     (None, 16, 16, 10)        321       \n",
      "_________________________________________________________________\n",
      "relu4 (QActivation)          (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (QConv2DBatchnorm)     (None, 8, 8, 7)           666       \n",
      "_________________________________________________________________\n",
      "relu5 (QActivation)          (None, 8, 8, 7)           0         \n",
      "_________________________________________________________________\n",
      "conv6 (QConv2DBatchnorm)     (None, 8, 8, 9)           613       \n",
      "_________________________________________________________________\n",
      "relu6 (QActivation)          (None, 8, 8, 9)           0         \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 4, 4, 9)           0         \n",
      "_________________________________________________________________\n",
      "conv7 (QConv2DBatchnorm)     (None, 4, 4, 2)           173       \n",
      "_________________________________________________________________\n",
      "relu7 (QActivation)          (None, 4, 4, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv8 (QConv2DBatchnorm)     (None, 4, 4, 10)          231       \n",
      "_________________________________________________________________\n",
      "relu8 (QActivation)          (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 2, 2, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "q_dense_9 (QDense)           (None, 5)                 205       \n",
      "_________________________________________________________________\n",
      "relu1_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "q_dense_10 (QDense)          (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "relu2_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "q_dense_11 (QDense)          (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "relu3_D (QActivation)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "output_softmax (QActivation) (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,619\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 17:15:49.111680: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/distillationClassKeras.py:60 train_step\n        distillation_loss = self.distillation_loss_fn(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1652 kl_divergence\n        return math_ops.reduce_sum(y_true * math_ops.log(y_true / y_pred), axis=-1)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1336 truediv\n        return _truediv_python3(x, y, name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1275 _truediv_python3\n        return gen_math_ops.real_div(x, y, name=name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:7346 real_div\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 10 and 3 for '{{node kl_divergence/truediv}} = RealDiv[T=DT_FLOAT](kl_divergence/clip_by_value, kl_divergence/clip_by_value_1)' with input shapes: [?,10], [?,3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m bestHP_BO_student \u001b[39m=\u001b[39m bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X23sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Training to obtain compressed model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X23sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m studentModel \u001b[39m=\u001b[39m studentCompression_2D_SOTA(bestHP_BO_student, images_train, images_test, y_train, y_test, teacherModel, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X23sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Model summary\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X23sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m studentModel\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/studentCompression.py:187\u001b[0m, in \u001b[0;36mstudentCompression_2D_SOTA\u001b[0;34m(bestHP, xTrain, xTest, yTrain, yTest, teacher_baseline, lr)\u001b[0m\n\u001b[1;32m    182\u001b[0m callbacks\u001b[39m.\u001b[39mappend(pruning_callbacks\u001b[39m.\u001b[39mUpdatePruningStep())\n\u001b[1;32m    184\u001b[0m \u001b[39m# Distill teacher to student \u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m history \u001b[39m=\u001b[39m distilledCNN\u001b[39m.\u001b[39;49mfit(xTrain, train_labels, \n\u001b[1;32m    188\u001b[0m                            batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, callbacks \u001b[39m=\u001b[39;49m callbacks)\n\u001b[1;32m    190\u001b[0m \u001b[39m# distilledCNN.student.save(\"models/distilled_student.h5\")\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mqkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _add_supported_quantized_objects\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    872\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2970\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3198\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3199\u001b[0m         args,\n\u001b[1;32m   3200\u001b[0m         kwargs,\n\u001b[1;32m   3201\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3202\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3203\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3204\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3205\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3206\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m    992\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/distillationClassKeras.py:60 train_step\n        distillation_loss = self.distillation_loss_fn(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1652 kl_divergence\n        return math_ops.reduce_sum(y_true * math_ops.log(y_true / y_pred), axis=-1)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1336 truediv\n        return _truediv_python3(x, y, name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1275 _truediv_python3\n        return gen_math_ops.real_div(x, y, name=name)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:7346 real_div\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 10 and 3 for '{{node kl_divergence/truediv}} = RealDiv[T=DT_FLOAT](kl_divergence/clip_by_value, kl_divergence/clip_by_value_1)' with input shapes: [?,10], [?,3].\n"
     ]
    }
   ],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 0\n",
    "    UPPER_FC = 2\n",
    "\n",
    "    # Grab best hyperparams\n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "    print(bestHP_BO_student)\n",
    "        \n",
    "    # Train 1D teacher model\n",
    "    studentModel = studentCompression_1D(bestHP_BO_student, xTrain, xTest, yTrain, yTest, teacherModel, lr)\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 1D teacher model\n",
    "    #studentModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression(bestHP_BO_student, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D.h5\")\n",
    "elif D_SIGNAL == 3:\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 8\n",
    "    UPPER_FC = 3\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression_2D_SOTA(bestHP_BO_student, images_train, images_test, y_train, y_test, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D_SOTA.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "if D_SIGNAL == 1:\n",
    "    # 1D signal\n",
    "    confusionMatrixPlot(studentModel, xTest_df_Final, yTest_Final)\n",
    "\n",
    "else:\n",
    "    # 2D signal\n",
    "    confusionMatrixPlot(studentModel, images_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
