{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:19.382306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.studentOptimization_1D import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherOptimization2D_SOTA import *\n",
    "from src.studentOptimization2D_SOTA import *\n",
    "\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n",
    "\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:20.842750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-11 15:17:20.863794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:20.863937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2023-07-11 15:17:20.863951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 15:17:20.864922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 15:17:20.864992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-11 15:17:20.866214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-11 15:17:20.866516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-11 15:17:20.867643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-11 15:17:20.868228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-11 15:17:20.870402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-11 15:17:20.870513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:20.870656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:20.870729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH_2D = \"dataset/pestControl\"\n",
    "ROOT_PATH_1D = r'dataset/cluster'\n",
    "\n",
    "\n",
    "# Class labels \n",
    "classLabels_2D = ['0', '1', '2']\n",
    "classLabels_1D = ['0', '1', '2', '3']\n",
    "\n",
    "nLabels = len(classLabels_1D)\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLES = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 0\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 1\n",
    "N_ITERATIONS_STUDENT = 100\n",
    "\n",
    "# Type of input -->  1: 1D signal, 2: 2D signal, 3: state-of-the art dataset\n",
    "D_SIGNAL = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel normalization\n",
    "def normalizationPix(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_ = train.astype('float32')\n",
    "    test_ = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_ = train_ / 255.0\n",
    "    test_ = test_ / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    # Load 1D signal dataset\n",
    "    xTrain, xTest, xTest_df_Final, yTrain, yTest, yTest_Final = loadDataset_1D(ROOT_PATH_1D, nLabels, SAMPLES)\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH_2D, classLabels_2D, ROWS, COLS)\n",
    "else: \n",
    "    # CIFAR-10 dataset\n",
    "    from keras.datasets import cifar10\n",
    "    (images_train, y_train), (images_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    images_train, images_test = normalizationPix(images_train, images_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "    \n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV+1):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "    for j in range (1, UPPER_FC+1):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "   \n",
    "    print(\"Best hyper-parameter configuration: \", bestHP)\n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher optimization\n",
      "INFO:tensorflow:Reloading Oracle from existing project tuner_teacher/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner_teacher/untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f96703409d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:22.477070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 15:17:22.499950: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304000000 Hz\n",
      "2023-07-11 15:17:22.500670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28292f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-11 15:17:22.500683: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-07-11 15:17:22.550480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.550715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b66fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-11 15:17:22.550732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2023-07-11 15:17:22.550956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.551072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2023-07-11 15:17:22.551100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 15:17:22.551143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 15:17:22.551150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-11 15:17:22.551157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-11 15:17:22.551164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-11 15:17:22.551171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-11 15:17:22.551177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-11 15:17:22.551184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-11 15:17:22.551221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.551314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.551382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-11 15:17:22.551398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-11 15:17:22.826711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-11 15:17:22.826732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-11 15:17:22.826736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-11 15:17:22.826950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.827079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 15:17:22.827167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1198 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    \n",
    "    if D_SIGNAL == 1:\n",
    "        print(\"1D signal\")\n",
    "        bestHP_BO_teacher = teacherBO_1D(xTrain, xTest, yTrain, yTest)\n",
    "    elif D_SIGNAL == 2:\n",
    "        print(\"2D signal\")\n",
    "        bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "        # Grab the best hyperparameters\n",
    "    else: \n",
    "        bestHP_BO_teacher = teacherBO_SOTA(images_train, y_train, images_test, y_test, N_ITERATIONS_TEACHER)\n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacherModel = load_model('models/CNN/teacher_NEW_v2_ok.h5')    \n",
    "    \n",
    "    teacherModel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter configuration:  [64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "[64, 64, 64, 64, 64, 96, 32, 64, 20, 50, 20]\n",
      "Tacher SOTA\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:23.421085: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n",
      "2023-07-11 15:17:23.624171: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:24.160320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-11 15:17:24.289943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/391 [..............................] - ETA: 12s - loss: 2.4982 - accuracy: 0.0885  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:17:25.301407: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2023-07-11 15:17:25.316380: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1023.69M (1073414144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-07-11 15:17:25.316570: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 921.32M (966072832 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 38ms/step - loss: 2.0023 - accuracy: 0.2775 - val_loss: 2.9212 - val_accuracy: 0.1478\n",
      "Epoch 2/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.3706 - accuracy: 0.5259 - val_loss: 1.3582 - val_accuracy: 0.5369\n",
      "Epoch 3/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.1799 - accuracy: 0.5976 - val_loss: 1.1606 - val_accuracy: 0.6012\n",
      "Epoch 4/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 1.0410 - accuracy: 0.6484 - val_loss: 1.1346 - val_accuracy: 0.6044\n",
      "Epoch 5/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.9461 - accuracy: 0.6848 - val_loss: 0.9925 - val_accuracy: 0.6658\n",
      "Epoch 6/32\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.8736 - accuracy: 0.7121 - val_loss: 0.9849 - val_accuracy: 0.6724\n",
      "Epoch 7/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.8026 - accuracy: 0.7366 - val_loss: 1.0183 - val_accuracy: 0.6673\n",
      "Epoch 8/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.7586 - accuracy: 0.7519 - val_loss: 0.9614 - val_accuracy: 0.6802\n",
      "Epoch 9/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.7229 - accuracy: 0.7660 - val_loss: 0.8653 - val_accuracy: 0.7136\n",
      "Epoch 10/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6753 - accuracy: 0.7819 - val_loss: 0.8380 - val_accuracy: 0.7242\n",
      "Epoch 11/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6425 - accuracy: 0.7952 - val_loss: 0.8405 - val_accuracy: 0.7257\n",
      "Epoch 12/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.6037 - accuracy: 0.8097 - val_loss: 0.8651 - val_accuracy: 0.7175\n",
      "Epoch 13/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5809 - accuracy: 0.8191 - val_loss: 0.8396 - val_accuracy: 0.7309\n",
      "Epoch 14/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5411 - accuracy: 0.8307 - val_loss: 0.9230 - val_accuracy: 0.7051\n",
      "Epoch 15/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.5125 - accuracy: 0.8402 - val_loss: 0.8278 - val_accuracy: 0.7382\n",
      "Epoch 16/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4828 - accuracy: 0.8518 - val_loss: 0.8154 - val_accuracy: 0.7381\n",
      "Epoch 17/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4529 - accuracy: 0.8632 - val_loss: 0.9168 - val_accuracy: 0.7170\n",
      "Epoch 18/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4361 - accuracy: 0.8694 - val_loss: 0.8109 - val_accuracy: 0.7533\n",
      "Epoch 19/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.4019 - accuracy: 0.8818 - val_loss: 0.8220 - val_accuracy: 0.7455\n",
      "Epoch 20/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3829 - accuracy: 0.8893 - val_loss: 0.8924 - val_accuracy: 0.7317\n",
      "Epoch 21/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3674 - accuracy: 0.8951 - val_loss: 0.9054 - val_accuracy: 0.7332\n",
      "Epoch 22/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3393 - accuracy: 0.9059 - val_loss: 0.9133 - val_accuracy: 0.7319\n",
      "Epoch 23/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.3174 - accuracy: 0.9127 - val_loss: 0.9129 - val_accuracy: 0.7377\n",
      "Epoch 24/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2912 - accuracy: 0.9232 - val_loss: 0.9238 - val_accuracy: 0.7409\n",
      "Epoch 25/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2744 - accuracy: 0.9297 - val_loss: 0.9064 - val_accuracy: 0.7453\n",
      "Epoch 26/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2573 - accuracy: 0.9359 - val_loss: 0.9166 - val_accuracy: 0.7467\n",
      "Epoch 27/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2369 - accuracy: 0.9444 - val_loss: 0.9569 - val_accuracy: 0.7426\n",
      "Epoch 28/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2170 - accuracy: 0.9510 - val_loss: 0.9777 - val_accuracy: 0.7436\n",
      "Epoch 29/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.2053 - accuracy: 0.9562 - val_loss: 1.0348 - val_accuracy: 0.7421\n",
      "Epoch 30/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.1855 - accuracy: 0.9645 - val_loss: 1.0479 - val_accuracy: 0.7463\n",
      "Epoch 31/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.1810 - accuracy: 0.9647 - val_loss: 1.0641 - val_accuracy: 0.7438\n",
      "Epoch 32/32\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.1684 - accuracy: 0.9671 - val_loss: 1.0674 - val_accuracy: 0.7475\n",
      "Model: \"teacherCNN_SOTA\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 8, 8, 96)          55392     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                49184     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "relu8 (Activation)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 258,726\n",
      "Trainable params: 258,214\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "if TEACHER_OP == 0:\n",
    "    if D_SIGNAL == 1:\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 0\n",
    "        UPPER_FC = 5\n",
    "\n",
    "        # Grab best hyperparams\n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 1D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, xTrain, xTest, yTrain, yTest, lr)\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 1D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "    elif D_SIGNAL == 2:\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 4\n",
    "        UPPER_FC = 3\n",
    "        \n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "        # Train 2D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D.h5\")\n",
    "    \n",
    "    elif D_SIGNAL == 3:\n",
    "        from src.teacherTraining2D_SOTA import teacherTrainingAfterBPO_SOTA\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 8\n",
    "        UPPER_FC = 3    \n",
    "\n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 2D teacher model - SOTA dataset\n",
    "        teacherModel = teacherTrainingAfterBPO_SOTA(bestHP_BO_teacher, images_train, images_test, y_train, y_test, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D_SOTA.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |?                 |conv_1\n",
      "5                 |?                 |conv_2\n",
      "3                 |?                 |conv_3\n",
      "10                |?                 |conv_4\n",
      "7                 |?                 |conv_5\n",
      "9                 |?                 |conv_6\n",
      "2                 |?                 |conv_7\n",
      "10                |?                 |conv_8\n",
      "5                 |?                 |fc1\n",
      "5                 |?                 |fc2\n",
      "5                 |?                 |fc3\n",
      "0.001             |?                 |learning_rate\n",
      "\n",
      "Epoch 1/32\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 80, 80, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80, 80, 3), dtype=tf.float32, name='q_conv2d_batchnorm_input'), name='q_conv2d_batchnorm_input', description=\"created by layer 'q_conv2d_batchnorm_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 15:25:34.458334: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:300 call  *\n        return self.layer.call(inputs, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/qkeras/qlayers.py:632 call  *\n        output = tf.keras.backend.dot(inputs, quantized_kernel)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:1898 dot\n        out = math_ops.matmul(x, y)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3314 matmul\n        return gen_math_ops.mat_mul(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5548 mat_mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 160 and 1000 for '{{node sequential/prune_low_magnitude_q_dense/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](sequential/prune_low_magnitude_flatten/Reshape, sequential/prune_low_magnitude_q_dense/add_4)' with input shapes: [?,160], [1000,5].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     bestHP_BO \u001b[39m=\u001b[39m studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melif\u001b[39;00m D_SIGNAL \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     bestHP_BO \u001b[39m=\u001b[39m studentBO_2D_SOTA(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)\n",
      "File \u001b[0;32m~/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/studentOptimization.py:197\u001b[0m, in \u001b[0;36mstudentBO_2D_SOTA\u001b[0;34m(images_train, y_train, images_test, y_test, teacher_baseline, N_ITERATIONS_STUDENT)\u001b[0m\n\u001b[1;32m    187\u001b[0m studentCNN_ \u001b[39m=\u001b[39m Distiller(student\u001b[39m=\u001b[39mbuild_model_QK_student, teacher\u001b[39m=\u001b[39mteacher_baseline)\n\u001b[1;32m    189\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mBayesianOptimization(\n\u001b[1;32m    190\u001b[0m     studentCNN_\u001b[39m.\u001b[39mstudent,\n\u001b[1;32m    191\u001b[0m     objective \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m     directory \u001b[39m=\u001b[39m OUTPUT_PATH\n\u001b[1;32m    195\u001b[0m )\n\u001b[0;32m--> 197\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m     x\u001b[39m=\u001b[39;49mimages_train, y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m    200\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(images_test, y_test),\n\u001b[1;32m    201\u001b[0m     batch_size\u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[1;32m    202\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[callbacks],\n\u001b[1;32m    203\u001b[0m     epochs\u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    207\u001b[0m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \n\u001b[1;32m    208\u001b[0m \u001b[39m#print(summary)\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    296\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m tuner_utils\u001b[39m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    872\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2970\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3198\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3199\u001b[0m         args,\n\u001b[1;32m   3200\u001b[0m         kwargs,\n\u001b[1;32m   3201\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3202\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3203\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3204\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3205\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3206\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m    992\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:300 call  *\n        return self.layer.call(inputs, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/qkeras/qlayers.py:632 call  *\n        output = tf.keras.backend.dot(inputs, quantized_kernel)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:1898 dot\n        out = math_ops.matmul(x, y)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3314 matmul\n        return gen_math_ops.mat_mul(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5548 mat_mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 160 and 1000 for '{{node sequential/prune_low_magnitude_q_dense/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](sequential/prune_low_magnitude_flatten/Reshape, sequential/prune_low_magnitude_q_dense/add_4)' with input shapes: [?,160], [1000,5].\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "if D_SIGNAL == 1:\n",
    "    bestHP_BO = studentBO_1D(xTrain, xTest, yTrain, yTest, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 2:\n",
    "    bestHP_BO = studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)\n",
    "elif D_SIGNAL == 3:\n",
    "    bestHP_BO = studentBO_2D_SOTA(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 0\n",
    "    UPPER_FC = 2\n",
    "\n",
    "    # Grab best hyperparams\n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "    print(bestHP_BO_student)\n",
    "        \n",
    "    # Train 1D teacher model\n",
    "    studentModel = studentCompression_1D(bestHP_BO_student, xTrain, xTest, yTrain, yTest, teacherModel, lr)\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 1D teacher model\n",
    "    #studentModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression(bestHP_BO_student, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D.h5\")\n",
    "elif D_SIGNAL == 3:\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "if D_SIGNAL == 1:\n",
    "    # 1D signal\n",
    "    confusionMatrixPlot(studentModel, xTest_df_Final, yTest_Final)\n",
    "\n",
    "else:\n",
    "    # 2D signal\n",
    "    confusionMatrixPlot(studentModel, images_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
