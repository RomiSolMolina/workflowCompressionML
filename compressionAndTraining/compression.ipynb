{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end workflow to efficiently compress and deploy DNN classifiers on SoC/FPGA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 15:59:15.472106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "from qkeras import *\n",
    "\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "\n",
    "#pip install scikit-image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "\n",
    "import shutil, sys\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Custom functions\n",
    "from src.distillationClassKeras import *\n",
    "\n",
    "# Plot confusion matrix\n",
    "from src.confMatrix import *\n",
    "\n",
    "from src.studentCompression import *\n",
    "from src.studentOptimization import *\n",
    "from src.studentOptimization_1D import *\n",
    "from src.teacherOptimization1D import *\n",
    "from src.teacherOptimization2D import *\n",
    "from src.teacherOptimization2D_SOTA import *\n",
    "from src.teacherTraining import *\n",
    "from src.loadDataset import *\n",
    "\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 15:59:17.498918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-05 15:59:17.935919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 15:59:17.936028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2023-07-05 15:59:17.936042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-05 15:59:17.937189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-05 15:59:17.937289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-05 15:59:17.938329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-05 15:59:17.938519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-05 15:59:17.939502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-05 15:59:17.940090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-05 15:59:17.942254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-05 15:59:17.942357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 15:59:17.942468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 15:59:17.942536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Dataset path\n",
    "ROOT_PATH_2D = \"dataset/pestControl\"\n",
    "ROOT_PATH_1D = r'dataset/cluster'\n",
    "\n",
    "\n",
    "# Class labels \n",
    "classLabels_2D = ['0', '1', '2']\n",
    "classLabels_1D = ['0', '1', '2', '3']\n",
    "\n",
    "nLabels = len(classLabels_1D)\n",
    "\n",
    "# Input shape for 2D dataset\n",
    "ROWS, COLS =  80, 80 \n",
    "\n",
    "# Input samples for 1D dataset\n",
    "SAMPLES = 30\n",
    "\n",
    "# Teacher model\n",
    "# 0: train teacher from scratch, 1: pre-trained model\n",
    "TEACHER_OP = 0\n",
    "\n",
    "# Number of iterations for BO\n",
    "N_ITERATIONS_TEACHER = 10\n",
    "N_ITERATIONS_STUDENT = 100\n",
    "\n",
    "# Type of input -->  1: 1D signal, 2: 2D signal, 3: state-of-the art dataset\n",
    "D_SIGNAL = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel normalization\n",
    "def normalizationPix(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_ = train.astype('float32')\n",
    "    test_ = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_ = train_ / 255.0\n",
    "    test_ = test_ / 255.0\n",
    "    # return normalized images\n",
    "    \n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    # Load 1D signal dataset\n",
    "    xTrain, xTest, xTest_df_Final, yTrain, yTest, yTest_Final = loadDataset_1D(ROOT_PATH_1D, nLabels, SAMPLES)\n",
    "\n",
    "elif D_SIGNAL == 2:\n",
    "    # Load 2D signal dataset\n",
    "    images_train, images_validation, images_test, y_train, y_test = loadDataset_2D(ROOT_PATH_2D, classLabels_2D, ROWS, COLS)\n",
    "else: \n",
    "    # CIFAR-10 dataset\n",
    "    from keras.datasets import cifar10\n",
    "    (images_train, y_train), (images_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    images_train, images_test = normalizationPix(images_train, images_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters\n",
    "\n",
    "def bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC):\n",
    "\n",
    "    bestHP = []\n",
    "    # Grab hyper-params\n",
    "    for i in range (1,UPPER_CONV):\n",
    "        bestHP.append(bestHP_BO.get(CONV_VAR + str(i)))\n",
    "    for j in range (1, UPPER_FC):\n",
    "        bestHP.append(bestHP_BO.get(FC_VAR + str(j)))\n",
    "    \n",
    "    return bestHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher optimization\n",
      "INFO:tensorflow:Reloading Oracle from existing project tuner_teacher/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner_teacher/untitled_project/tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "292               |212               |fc1\n",
      "92                |72                |fc2\n",
      "10                |20                |fc3\n",
      "50                |30                |fc4\n",
      "0.0001            |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 16:01:00.969679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-05 16:01:01.299006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 5ms/step - loss: 2.0503 - accuracy: 0.2789 - val_loss: 1.5535 - val_accuracy: 0.4743\n",
      "Epoch 2/32\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4329 - accuracy: 0.5184 - val_loss: 1.2258 - val_accuracy: 0.5926\n",
      "Epoch 3/32\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1415 - accuracy: 0.6235 - val_loss: 1.1823 - val_accuracy: 0.6129\n",
      "Epoch 4/32\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9998 - accuracy: 0.6706 - val_loss: 1.0217 - val_accuracy: 0.6615\n",
      "Epoch 5/32\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8883 - accuracy: 0.7134 - val_loss: 1.0195 - val_accuracy: 0.6656\n",
      "Epoch 6/32\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7978 - accuracy: 0.7453 - val_loss: 0.9781 - val_accuracy: 0.6906\n",
      "Epoch 7/32\n",
      " 229/1563 [===>..........................] - ETA: 6s - loss: 0.7091 - accuracy: 0.7766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         bestHP_BO_teacher \u001b[39m=\u001b[39m teacherBO(images_train, y_train, images_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# Grab the best hyperparameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         bestHP_BO_teacher \u001b[39m=\u001b[39m teacherBO_SOTA(images_train, y_train, images_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Load pre-trained model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ro/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/compression.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     teacherModel \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmodels/CNN/teacher_NEW_v2_ok.h5\u001b[39m\u001b[39m'\u001b[39m)    \n",
      "File \u001b[0;32m~/kaleido/repo/workflowCompressionML_repo/compressionAndTraining/src/teacherOptimization2D_SOTA.py:118\u001b[0m, in \u001b[0;36mteacherBO_SOTA\u001b[0;34m(images_train, y_train, images_test, y_test)\u001b[0m\n\u001b[1;32m    108\u001b[0m         shutil\u001b[39m.\u001b[39mrmtree(OUTPUT_PATH, ignore_errors \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m     tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mBayesianOptimization(\n\u001b[1;32m    111\u001b[0m         build_model,\n\u001b[1;32m    112\u001b[0m         objective \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         directory \u001b[39m=\u001b[39m OUTPUT_PATH\n\u001b[1;32m    116\u001b[0m )\n\u001b[0;32m--> 118\u001b[0m     tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m         x\u001b[39m=\u001b[39;49mimages_train, y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m    121\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(images_test, y_test),\n\u001b[1;32m    122\u001b[0m         batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[1;32m    123\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[callbacks],\n\u001b[1;32m    124\u001b[0m         epochs\u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \n\u001b[1;32m    130\u001b[0m     \u001b[39m#print(summary)\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    296\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m tuner_utils\u001b[39m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(callback, \u001b[39m'\u001b[39m\u001b[39m_supports_tf_logs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[39mif\u001b[39;00m numpy_logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49mto_numpy_or_python_type(logs)\n\u001b[1;32m   1085\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    509\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, ops\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 510\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1036\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1038\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     six\u001b[39m.\u001b[39mraise_from(core\u001b[39m.\u001b[39m_status_to_exception(e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmessage), \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Decide if optimize a teacher architecture or load a pre-trained network as teacher\n",
    "\n",
    "if TEACHER_OP == 0:\n",
    "    # optimize teacher architecture\n",
    "    print(\"Teacher optimization\")\n",
    "    \n",
    "    if D_SIGNAL == 1:\n",
    "        print(\"1D signal\")\n",
    "        bestHP_BO_teacher = teacherBO_1D(xTrain, xTest, yTrain, yTest)\n",
    "    elif D_SIGNAL == 2:\n",
    "        print(\"2D signal\")\n",
    "        bestHP_BO_teacher = teacherBO(images_train, y_train, images_test, y_test)\n",
    "        # Grab the best hyperparameters\n",
    "    else: \n",
    "        bestHP_BO_teacher = teacherBO_SOTA(images_train, y_train, images_test, y_test)\n",
    "else: \n",
    "\n",
    "    # Load pre-trained model\n",
    "    teacherModel = load_model('models/CNN/teacher_NEW_v2_ok.h5')    \n",
    "    \n",
    "    teacherModel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the best hyperparameters for teacher training\n",
    "if TEACHER_OP == 0:\n",
    "    if D_SIGNAL == 1:\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 0\n",
    "        UPPER_FC = 5\n",
    "\n",
    "        # Grab best hyperparams\n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "        print(bestHP_BO_teacher)\n",
    "        \n",
    "        # Train 1D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, xTrain, xTest, yTrain, yTest, lr)\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # Save model 1D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        lr = bestHP_BO_teacher.get('learning_rate')\n",
    "        CONV_VAR = 'conv_'\n",
    "        FC_VAR = 'fc'\n",
    "        UPPER_CONV = 4\n",
    "        UPPER_FC = 3\n",
    "        \n",
    "        # Grab best hyperparams    \n",
    "        bestHP_BO_teacher = bestHPBO_computation(bestHP_BO_teacher, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "        # Train 2D teacher model\n",
    "        teacherModel = teacherTrainingAfterBPO(bestHP_BO_teacher, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "        teacherModel.summary()\n",
    "\n",
    "        # # Save model 2D teacher model\n",
    "        teacherModel.save(\"models/teacherFP_2D.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for student architecture\n",
    "if D_SIGNAL == 1:\n",
    "    bestHP_BO = studentBO_1D(xTrain, xTest, yTrain, yTest, teacherModel, N_ITERATIONS_STUDENT)\n",
    "else:\n",
    "    bestHP_BO = studentBO_2D(images_train, y_train, images_test, y_test, teacherModel, N_ITERATIONS_STUDENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_SIGNAL == 1:\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 0\n",
    "    UPPER_FC = 2\n",
    "\n",
    "    # Grab best hyperparams\n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "    print(bestHP_BO_student)\n",
    "        \n",
    "    # Train 1D teacher model\n",
    "    studentModel = studentCompression_1D(bestHP_BO_student, xTrain, xTest, yTrain, yTest, teacherModel, lr)\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 1D teacher model\n",
    "    #studentModel.save(\"models/teacherFP_1D.h5\")\n",
    "\n",
    "else:\n",
    "\n",
    "    CONV_VAR = 'conv_'\n",
    "    FC_VAR = 'fc'\n",
    "    UPPER_CONV = 9\n",
    "    UPPER_FC = 4\n",
    "    lr = bestHP_BO.get('learning_rate')\n",
    "\n",
    "    # Grab best hyperparams    \n",
    "    bestHP_BO_student = bestHPBO_computation(bestHP_BO, CONV_VAR, FC_VAR, UPPER_CONV, UPPER_FC)\n",
    "\n",
    "    # Training to obtain compressed model\n",
    "    studentModel = studentCompression(bestHP_BO_student, images_train, y_train, teacherModel, lr)\n",
    "\n",
    "    # Model summary\n",
    "    studentModel.summary()\n",
    "\n",
    "    # Save model 2D teacher model\n",
    "    #studentModel.save(\"models/studentModel_2D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for accuracy evaluation\n",
    "if D_SIGNAL == 1:\n",
    "    # 1D signal\n",
    "    confusionMatrixPlot(studentModel, xTest_df_Final, yTest_Final)\n",
    "\n",
    "else:\n",
    "    # 2D signal\n",
    "    confusionMatrixPlot(studentModel, images_train, y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
